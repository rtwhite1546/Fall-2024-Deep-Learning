{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5eaca6a-9170-407f-a4c2-4f08a0736b15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MTH 4320 / 5320 - Homework 2\n",
    "\n",
    "## Dense and Convolutional Neural Networks and PyTorch\n",
    "\n",
    "**Deadline**: Oct 17\n",
    "\n",
    "**Max Points**: 100 (graduate students) or 100+10 (undergraduate students)\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Submit **one** Python notebook file for grading. Your file must include **text explanations** of your work, **well-commented code**, and the **outputs** from your code.\n",
    "\n",
    "### Problems\n",
    "\n",
    "#### Dense Neural Networks\n",
    "\n",
    "1. [10 points] Consider a dense neural network classifier with 2D input, 1 hidden layer with 3 neurons with ReLU activation, and 3D output with softmax. Generate random numbers for the weights and compute the output for $(4, 5)$. Then, compute the gradient with respect to the weights using backpropagation for a MSE loss. (Paper and pencil question)\n",
    "\n",
    "2. [30 points] Use a feedforward NN to classify the CIFAR-10 dataset, and tune its hyperparameters as best you can. **You must use PyTorch**. Requirements below.\n",
    "\n",
    "Randomly split the dataset into 60\\%/20/\\%/20\\% training/validation/testing sets. When tuning hyperparameters, test on the validation set. After you find the best hyperparameters, run your code **once** with these settings on the test. Use `random_state = 1` before splitting data.\n",
    "\n",
    "Start with a single 10-node hidden layer as a benchmark.\n",
    "\n",
    "You must run **at least one experiment** using all major techniques (5 points each):\n",
    "\n",
    "* Normalization/Standardization\n",
    "* Weight Initialization\n",
    "* Architectures\n",
    "* Activation functions\n",
    "* Loss functions\n",
    "* Regularization (must include dropout)\n",
    "\n",
    "**For each experiment, document why you chose to run this experiment, training accuracy/loss, validation accuracy/loss, epoch number with best validation accuracy (use early stopping), and training runtime.**\n",
    "\n",
    "Training takes significant time, so brute force is *not* feasible. Make *informed decisions* on how to proceed and write your reasoning in your report. Include all fruitful experiments you run along the way. More importantly than the results, I want to see that you are *thinking well* and making good decisions. Good results will come from eventually if you *understand what you are doing*.\n",
    "\n",
    "**Explanations and reasoning for your progression = [10 points]**\n",
    "\n",
    "#### Convolutional Neural Networks (CNNs)\n",
    "\n",
    "3. [40 points] Repeat problem 2 using a CNN and the Imagenette dataset. Run at least 10 training experiments, but you are free to use any techniques you choose, but much of the credit is based on your reasoning: your progression requires rationale for why you're tuning the hyperparmeterse you choose to tune. **Required**: Experiment with **data augmentation**. [GPU computing is recommended for this.]\n",
    "\n",
    "4. [Required for graduate students (10 points), bonus for undergrads] Derive the formula for backpropagating gradients through a convolutional layer.\n",
    "\n",
    "5. [Required for graduate students (10 points), bonus for undergrads] Give a detailed accounting of the number of parameters in your best model from Problem 3. (*Hint.* PyTorch will give you a parameter count--your job is to write up how it's computed based on your architecture.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97aec40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
